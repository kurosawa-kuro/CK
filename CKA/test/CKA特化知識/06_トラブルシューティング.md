# CKA特化: トラブルシューティング

## 概要

トラブルシューティングはCKA試験の**約30%**を占める最重要領域。
系統的なアプローチを身につけることが合格の鍵。

---

## トラブルシューティングの基本フロー

```
1. 状況把握 (kubectl get)
    ↓
2. 詳細確認 (kubectl describe)
    ↓
3. ログ確認 (kubectl logs / journalctl)
    ↓
4. 設定確認 (マニフェスト / 設定ファイル)
    ↓
5. 修正 (kubectl edit / systemctl)
```

---

## 1. Pod のトラブルシューティング

### Pod状態と初手コマンド

| Pod Status | 意味 | 初手コマンド |
|-----------|------|-------------|
| Pending | スケジュール待ち | `kubectl describe pod` |
| ContainerCreating | イメージPull中 | `kubectl describe pod` |
| ImagePullBackOff | イメージ取得失敗 | `kubectl describe pod` |
| CrashLoopBackOff | 起動後にクラッシュ | `kubectl logs` |
| Running | 正常動作 | - |
| Error | エラー終了 | `kubectl logs` |
| Completed | 正常終了 | - |

### Pending の原因

```bash
# 確認コマンド
kubectl describe pod <pod-name>

# Events を確認して原因特定
```

| 原因 | Events メッセージ | 対処 |
|------|------------------|------|
| リソース不足 | Insufficient cpu/memory | requests を下げる or ノード追加 |
| nodeSelector不一致 | node(s) didn't match | ラベルを確認 |
| Taint/Toleration | node(s) had taints | Toleration追加 |
| PVC未バインド | persistentvolumeclaim not found | PVCを確認 |

### ImagePullBackOff の原因

```bash
# 確認コマンド
kubectl describe pod <pod-name> | grep -A5 Events

# よくある原因
- イメージ名のタイポ
- タグの間違い
- プライベートレジストリの認証エラー
- ネットワーク問題
```

### CrashLoopBackOff の原因

```bash
# ログ確認（最重要）
kubectl logs <pod-name>

# 前回のログ
kubectl logs <pod-name> --previous

# よくある原因
- コマンドの間違い
- 設定ファイルのエラー
- 依存サービスへの接続失敗
- メモリ不足 (OOMKilled)
```

---

## 2. Node のトラブルシューティング

### Node状態の確認

```bash
# ノード状態
kubectl get nodes

# 詳細確認
kubectl describe node <node-name>
```

### NotReady の原因と対処

```
Node NotReady の主な原因:
1. kubelet が停止している
2. ネットワーク問題
3. ディスク容量不足
4. メモリ不足
```

### kubelet の確認（ノード上で実行）

```bash
# SSH でノードに接続
ssh <node-name>

# kubelet のステータス確認
systemctl status kubelet

# kubelet のログ確認
journalctl -u kubelet -f

# kubelet を再起動
systemctl restart kubelet
```

### ノードの Conditions 確認

```bash
kubectl describe node <node-name> | grep -A10 Conditions

# Conditions の種類
- Ready: kubelet が正常
- MemoryPressure: メモリ不足
- DiskPressure: ディスク不足
- PIDPressure: プロセス過多
- NetworkUnavailable: ネットワーク問題
```

---

## 3. コントロールプレーンのトラブルシューティング

### コントロールプレーンPodの確認

```bash
# kube-system の Pod を確認
kubectl get pods -n kube-system

# 詳細確認
kubectl describe pod <pod-name> -n kube-system

# ログ確認
kubectl logs <pod-name> -n kube-system
```

### 静的Podのトラブルシューティング

```bash
# 静的Podのマニフェストは以下にある
ls /etc/kubernetes/manifests/

# 主要な静的Pod
- kube-apiserver.yaml
- kube-controller-manager.yaml
- kube-scheduler.yaml
- etcd.yaml

# マニフェストを修正すると自動的に再起動される
vi /etc/kubernetes/manifests/kube-apiserver.yaml
```

### APIサーバーが動かない場合

```bash
# kubelet のログを確認（APIサーバーの起動エラー）
journalctl -u kubelet | grep apiserver

# 静的Podのマニフェストを確認
cat /etc/kubernetes/manifests/kube-apiserver.yaml

# よくある原因
- 証明書パスの間違い
- ポート番号の間違い
- etcdのエンドポイントエラー
```

---

## 4. Service のトラブルシューティング

### Serviceの通信確認

```bash
# Service の確認
kubectl get svc <service-name>

# Endpoints の確認（重要！）
kubectl get endpoints <service-name>

# Endpoints が空の場合 → selector が不一致
```

### ServiceとPodの紐付け確認

```bash
# Service の selector を確認
kubectl describe svc <service-name>

# Pod の labels を確認
kubectl get pods --show-labels

# selector と labels が一致しているか確認
```

### よくある問題

| 問題 | 原因 | 対処 |
|-----|------|------|
| Endpoints が空 | selector不一致 | Serviceのselectorを修正 |
| 接続できない | targetPortが間違い | Pod側のポートと一致させる |
| 名前解決できない | CoreDNS問題 | CoreDNS Podを確認 |

---

## 5. DNS のトラブルシューティング

### CoreDNS の確認

```bash
# CoreDNS の Pod 確認
kubectl get pods -n kube-system -l k8s-app=kube-dns

# CoreDNS のログ
kubectl logs -n kube-system -l k8s-app=kube-dns

# CoreDNS の ConfigMap
kubectl get configmap coredns -n kube-system -o yaml
```

### DNS テスト

```bash
# テスト用 Pod を起動
kubectl run test --image=busybox:1.28 --rm -it -- sh

# DNS テスト
nslookup kubernetes.default
nslookup <service-name>.<namespace>.svc.cluster.local
```

---

## 6. ネットワークのトラブルシューティング

### kube-proxy の確認

```bash
# kube-proxy の確認
kubectl get pods -n kube-system | grep kube-proxy

# kube-proxy のログ
kubectl logs -n kube-system -l k8s-app=kube-proxy
```

### Pod間通信テスト

```bash
# テストPod から他のPodへ通信
kubectl exec -it <pod-name> -- curl <target-pod-ip>:<port>

# Service経由でテスト
kubectl exec -it <pod-name> -- curl <service-name>:<port>
```

### NetworkPolicy の確認

```bash
# NetworkPolicy 一覧
kubectl get networkpolicy -A

# 詳細確認
kubectl describe networkpolicy <name> -n <namespace>

# NetworkPolicy が通信をブロックしている可能性
```

---

## 7. ストレージのトラブルシューティング

### PVC が Bound にならない

```bash
# PVC 状態確認
kubectl get pvc

# PV 状態確認
kubectl get pv

# 詳細確認
kubectl describe pvc <pvc-name>
kubectl describe pv <pv-name>
```

### PV-PVC マッチ条件

| 項目 | 条件 |
|-----|------|
| capacity | PV >= PVC |
| accessModes | 一致が必要 |
| storageClassName | 一致が必要（空も含む） |
| volumeMode | 一致が必要 |

---

## 8. 証明書のトラブルシューティング

### 証明書の有効期限確認

```bash
# kubeadm で確認
kubeadm certs check-expiration

# openssl で確認
openssl x509 -in /etc/kubernetes/pki/apiserver.crt -noout -dates
```

### 証明書の更新

```bash
# 全証明書を更新
kubeadm certs renew all

# 個別に更新
kubeadm certs renew apiserver
```

---

## トラブルシューティングチェックリスト

### Pod が動かない
```
□ kubectl get pods で状態確認
□ kubectl describe pod で Events 確認
□ kubectl logs でログ確認
□ イメージ名/タグは正しいか
□ リソース要求は適切か
□ nodeSelector/Toleration は正しいか
```

### Node が NotReady
```
□ ssh でノードに接続
□ systemctl status kubelet
□ journalctl -u kubelet
□ ディスク容量 (df -h)
□ メモリ (free -m)
□ systemctl restart kubelet
```

### Service に接続できない
```
□ kubectl get endpoints で確認
□ selector と labels が一致するか
□ targetPort は正しいか
□ Pod は Running か
□ NetworkPolicy がブロックしていないか
```

### コントロールプレーン障害
```
□ kubectl get pods -n kube-system
□ /etc/kubernetes/manifests/ の確認
□ journalctl -u kubelet
□ 証明書の有効期限
□ etcd の状態
```

---

## 重要コマンド集

```bash
# 状態確認
kubectl get pods -A
kubectl get nodes
kubectl get events --sort-by='.lastTimestamp'

# 詳細確認
kubectl describe pod <pod>
kubectl describe node <node>

# ログ確認
kubectl logs <pod>
kubectl logs <pod> --previous
kubectl logs <pod> -c <container>

# ノード上での確認
systemctl status kubelet
journalctl -u kubelet
journalctl -u kubelet | tail -100

# ネットワーク確認
kubectl get endpoints
kubectl get svc
kubectl exec -it <pod> -- curl <target>

# 設定確認
cat /etc/kubernetes/manifests/*.yaml
cat /var/lib/kubelet/config.yaml
```

---

## ミニ演習（kind対応）

### 演習1: ImagePullBackOff の調査と修正

```bash
# 壊れたPodを作成
kubectl run broken-image --image=nginx:nonexistent-tag-12345

# 状態確認（ImagePullBackOff/ErrImagePull）
kubectl get pod broken-image

# 詳細確認
kubectl describe pod broken-image | grep -A 10 Events

# 修正：Podを削除して正しいイメージで再作成
kubectl delete pod broken-image
kubectl run broken-image --image=nginx:alpine

# 確認
kubectl get pod broken-image
```

### 演習2: Pending Podの調査

```bash
# リソース要求が大きすぎるPodを作成
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: resource-hog
spec:
  containers:
  - name: nginx
    image: nginx
    resources:
      requests:
        memory: "100Gi"
        cpu: "100"
EOF

# 状態確認（Pending）
kubectl get pod resource-hog

# 詳細確認（FailedScheduling）
kubectl describe pod resource-hog | grep -A 5 Events

# クリーンアップ
kubectl delete pod resource-hog
```

### 演習3: Service接続問題の調査

```bash
# バックエンドPodを作成
kubectl run backend --image=nginx --port=80 --labels="app=backend"

# 間違ったSelectorでServiceを作成
kubectl expose pod backend --name=wrong-svc --port=80 --selector="app=wrong-label"

# Endpoints確認（空になっている）
kubectl get endpoints wrong-svc

# 調査
kubectl describe svc wrong-svc | grep Selector
kubectl get pod backend --show-labels

# 修正
kubectl patch svc wrong-svc -p '{"spec":{"selector":{"app":"backend"}}}'

# 確認
kubectl get endpoints wrong-svc

# クリーンアップ
kubectl delete pod backend
kubectl delete svc wrong-svc
```

### 演習4: CrashLoopBackOff の調査

```bash
# 必ず失敗するPodを作成
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: crash-pod
spec:
  containers:
  - name: fail
    image: busybox
    command: ["sh", "-c", "exit 1"]
EOF

# 状態確認（CrashLoopBackOff）
sleep 30
kubectl get pod crash-pod

# ログ確認
kubectl logs crash-pod

# 前回のログ確認
kubectl logs crash-pod --previous

# クリーンアップ
kubectl delete pod crash-pod
```
